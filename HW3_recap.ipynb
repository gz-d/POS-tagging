{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ba69bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import functools as fc\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ad6f16",
   "metadata": {},
   "source": [
    "## Task 1: Vocabulary Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7115d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train = pd.read_csv('hw3/data/train', sep='\\t', names=['index', 'word', 'POS'])\n",
    "train = pd.read_csv('data/train', sep='\\t', names=['index', 'word', 'POS'])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d95f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = train['word'].values.tolist()\n",
    "index = train['index'].values.tolist()\n",
    "pos = train['POS'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d6b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {}\n",
    "\n",
    "for i in range(len(word)):\n",
    "    if word[i] in vocab:\n",
    "        vocab[word[i]] += 1\n",
    "    else:\n",
    "        vocab[word[i]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace rare words with <unk> (threshold = 3)\n",
    "vocab2 = {}\n",
    "num_unk = 0\n",
    "\n",
    "for w in vocab:\n",
    "    if vocab[w] >= 3:\n",
    "        vocab2[w] = vocab[w]\n",
    "    else:\n",
    "        num_unk += vocab[w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c6a448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the vocabulary by occurrences of words\n",
    "vocab_sorted = sorted(vocab.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff3fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the sorted vocabulary to vocab file\n",
    "#with open('recap/vocab.txt', 'w') as vocab_file:\n",
    "with open('output/vocab.txt', 'w') as vocab_file:\n",
    "    # the format of the vocab is word index occurrence\n",
    "    # we add <unk> to the top of the vocabulary manually\n",
    "    vocab_file.write('<unk>' + '\\t' + str(0) + '\\t' + str(num_unk) + '\\n')\n",
    "    for i in range(len(vocab_sorted)):\n",
    "        vocab_file.write(vocab_sorted[i][0] + '\\t' + str(i+1) + '\\t' + str(vocab_sorted[i][1]) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The total size of my vocabulary is {len(vocab_sorted)}\\n')\n",
    "print(f'The total occurrences of <unk> is {num_unk}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc524d9",
   "metadata": {},
   "source": [
    "## Task 2: Model Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b03413",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary list with only frequent words (i.e. occur no less than 3 times)\n",
    "vocab_ls = list(vocab2.keys())\n",
    "\n",
    "# write the frequent words into a json file\n",
    "#with open('recap/vocab_frequent.txt', 'w') as output:\n",
    "with open('output/vocab_frequent.txt', 'w') as output:\n",
    "    for word in vocab_ls:\n",
    "        output.write(word + '\\n')\n",
    "\n",
    "# replace non-frequent words in word with <unk>\n",
    "for i in range(len(word)):\n",
    "    if word[i] not in vocab_ls:\n",
    "        word[i] = '<unk>'\n",
    "\n",
    "# count (s, s') and (s, x) pairs\n",
    "ss = {}\n",
    "sx = {}\n",
    "for i in range(len(word)-1):\n",
    "    # make sure the index of the current word is less than the next\n",
    "    # ss = {pos[i+1]|pos[i]: count}\n",
    "    # we are not using the format {(pos[i], pos[i+1]): count} because\n",
    "    # json doesn't support tuple\n",
    "    if index[i] < index[i+1]:\n",
    "        if str(pos[i+1]) + '|' + str(pos[i]) in ss:\n",
    "            ss[str(pos[i+1]) + '|' + str(pos[i])] +=1\n",
    "        else:\n",
    "            ss[str(pos[i+1]) + '|' + str(pos[i])] = 1\n",
    "            \n",
    "        if str(word[i]) + '|' + str(pos[i]) in sx:\n",
    "            sx[str(word[i]) + '|' + str(pos[i])] +=1\n",
    "        else:\n",
    "            sx[str(word[i]) + '|' + str(pos[i])] = 1\n",
    "            \n",
    "# for ss, we need to count the times that a pos tag occurs at the beginning\n",
    "# of a sequence (i.e. (s|<s>))\n",
    "for i in range(len(word)):\n",
    "    if index[i] == 1:\n",
    "        if str(pos[i]) + '|' + '<s>' in ss:\n",
    "            ss[str(pos[i]) + '|' + '<s>'] += 1\n",
    "        else:\n",
    "            ss[str(pos[i]) + '|' + '<s>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28086bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build an emission and a transition dictionaries\n",
    "emission = {}\n",
    "transition = {}\n",
    "\n",
    "# count occurrences of pos tags\n",
    "count_pos = {}\n",
    "\n",
    "for p in pos:\n",
    "    if p in count_pos:\n",
    "        count_pos[p] += 1\n",
    "    else:\n",
    "        count_pos[p] = 1\n",
    "        \n",
    "# don't forget to count the occurrences of <start>\n",
    "count_pos['<s>'] = 0\n",
    "for i in index:\n",
    "    if i == 1:\n",
    "        count_pos['<s>'] += 1\n",
    "\n",
    "# emission dictionary {(s, x): count(s, x) / count(s)}\n",
    "for sx_pair in sx:\n",
    "    emission[sx_pair] = sx[sx_pair] / count_pos[sx_pair.split('|')[1]]\n",
    "\n",
    "# transition dictionary {(s, s'): count(s, s') / count(s)}\n",
    "for ss_pair in ss:\n",
    "    transition[ss_pair] = ss[ss_pair] / count_pos[ss_pair.split('|')[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea665d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(transition)} transition parameters in my HMM\\n')\n",
    "print(f'There are {len(emission)} emission parameters in my HMM\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a4c8f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the emission and transition dictionaries into a json file\n",
    "emission_transition = [emission, transition]\n",
    "#with open('recap/hmm.json', 'w') as output:\n",
    "with open('output/hmm.json', 'w') as output:\n",
    "    json.dump(emission_transition, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02684bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a list of distinct pos\n",
    "pos_distinct = list(count_pos.keys())\n",
    "\n",
    "# write the pos_distinct into a txt file\n",
    "#with open('recap/pos.txt', 'w') as pos_output:\n",
    "with open('output/pos.txt', 'w') as pos_output:\n",
    "    for _, pos in enumerate(pos_distinct):\n",
    "        pos_output.write(pos + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bb1da0",
   "metadata": {},
   "source": [
    "## Task 3: Greedy Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "39fb7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file vocab\n",
    "vocab_frequent = []\n",
    "#with open('recap/vocab_frequent.txt', 'r') as vocab_txt:\n",
    "with open('output/vocab_frequent.txt', 'r') as vocab_txt:\n",
    "    for word in vocab_txt:\n",
    "        word = word.strip('\\n')\n",
    "        vocab_frequent.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48019ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pierre',\n",
       " ',',\n",
       " '61',\n",
       " 'years',\n",
       " 'old',\n",
       " 'will',\n",
       " 'join',\n",
       " 'the',\n",
       " 'board',\n",
       " 'as',\n",
       " 'a',\n",
       " 'nonexecutive',\n",
       " 'director',\n",
       " 'Nov.',\n",
       " '29',\n",
       " '.',\n",
       " 'Mr.',\n",
       " 'is',\n",
       " 'chairman',\n",
       " 'of',\n",
       " 'N.V.',\n",
       " 'Dutch',\n",
       " 'publishing',\n",
       " 'group',\n",
       " 'Rudolph',\n",
       " 'Agnew',\n",
       " '55',\n",
       " 'and',\n",
       " 'former',\n",
       " 'Consolidated',\n",
       " 'Gold',\n",
       " 'Fields',\n",
       " 'PLC',\n",
       " 'was',\n",
       " 'named',\n",
       " 'this',\n",
       " 'British',\n",
       " 'industrial',\n",
       " 'conglomerate',\n",
       " 'A',\n",
       " 'form',\n",
       " 'asbestos',\n",
       " 'once',\n",
       " 'used',\n",
       " 'to',\n",
       " 'make',\n",
       " 'Kent',\n",
       " 'cigarette',\n",
       " 'filters',\n",
       " 'has',\n",
       " 'caused',\n",
       " 'high',\n",
       " 'percentage',\n",
       " 'cancer',\n",
       " 'deaths',\n",
       " 'among',\n",
       " 'workers',\n",
       " 'exposed',\n",
       " 'it',\n",
       " 'more',\n",
       " 'than',\n",
       " '30',\n",
       " 'ago',\n",
       " 'researchers',\n",
       " 'reported',\n",
       " 'The',\n",
       " 'fiber',\n",
       " 'crocidolite',\n",
       " 'unusually',\n",
       " 'resilient',\n",
       " 'enters',\n",
       " 'lungs',\n",
       " 'with',\n",
       " 'even',\n",
       " 'brief',\n",
       " 'exposures',\n",
       " 'causing',\n",
       " 'symptoms',\n",
       " 'that',\n",
       " 'show',\n",
       " 'up',\n",
       " 'decades',\n",
       " 'later',\n",
       " 'said',\n",
       " 'Lorillard',\n",
       " 'Inc.',\n",
       " 'unit',\n",
       " 'New',\n",
       " 'York-based',\n",
       " 'Loews',\n",
       " 'Corp.',\n",
       " 'makes',\n",
       " 'cigarettes',\n",
       " 'stopped',\n",
       " 'using',\n",
       " 'in',\n",
       " 'its',\n",
       " '1956',\n",
       " 'Although',\n",
       " 'preliminary',\n",
       " 'findings',\n",
       " 'were',\n",
       " 'year',\n",
       " 'latest',\n",
       " 'results',\n",
       " 'appear',\n",
       " 'today',\n",
       " \"'s\",\n",
       " 'England',\n",
       " 'Journal',\n",
       " 'Medicine',\n",
       " 'forum',\n",
       " 'likely',\n",
       " 'bring',\n",
       " 'new',\n",
       " 'attention',\n",
       " 'problem',\n",
       " '``',\n",
       " 'This',\n",
       " 'an',\n",
       " 'story',\n",
       " 'We',\n",
       " \"'re\",\n",
       " 'talking',\n",
       " 'about',\n",
       " 'before',\n",
       " 'anyone',\n",
       " 'heard',\n",
       " 'having',\n",
       " 'any',\n",
       " 'questionable',\n",
       " 'properties',\n",
       " 'There',\n",
       " 'no',\n",
       " 'our',\n",
       " 'products',\n",
       " 'now',\n",
       " \"''\",\n",
       " 'Neither',\n",
       " 'nor',\n",
       " 'who',\n",
       " 'studied',\n",
       " 'aware',\n",
       " 'research',\n",
       " 'on',\n",
       " 'smokers',\n",
       " 'have',\n",
       " 'useful',\n",
       " 'information',\n",
       " 'whether',\n",
       " 'users',\n",
       " 'are',\n",
       " 'at',\n",
       " 'risk',\n",
       " 'James',\n",
       " 'A.',\n",
       " 'Talcott',\n",
       " 'Boston',\n",
       " 'Cancer',\n",
       " 'Institute',\n",
       " 'Dr.',\n",
       " 'led',\n",
       " 'team',\n",
       " 'from',\n",
       " 'National',\n",
       " 'medical',\n",
       " 'schools',\n",
       " 'Harvard',\n",
       " 'University',\n",
       " 'spokeswoman',\n",
       " 'very',\n",
       " 'modest',\n",
       " 'amounts',\n",
       " 'making',\n",
       " 'paper',\n",
       " 'for',\n",
       " 'early',\n",
       " '1950s',\n",
       " 'replaced',\n",
       " 'different',\n",
       " 'type',\n",
       " 'From',\n",
       " '1953',\n",
       " '1955',\n",
       " '9.8',\n",
       " 'billion',\n",
       " 'sold',\n",
       " 'company',\n",
       " 'Among',\n",
       " '33',\n",
       " 'men',\n",
       " 'worked',\n",
       " 'closely',\n",
       " 'substance',\n",
       " '28',\n",
       " 'died',\n",
       " '--',\n",
       " 'three',\n",
       " 'times',\n",
       " 'expected',\n",
       " 'number',\n",
       " 'Four',\n",
       " 'five',\n",
       " 'surviving',\n",
       " 'asbestos-related',\n",
       " 'diseases',\n",
       " 'including',\n",
       " 'recently',\n",
       " 'diagnosed',\n",
       " 'total',\n",
       " '18',\n",
       " 'malignant',\n",
       " 'lung',\n",
       " 'far',\n",
       " 'higher',\n",
       " 'rate',\n",
       " 'striking',\n",
       " 'finding',\n",
       " 'those',\n",
       " 'us',\n",
       " 'study',\n",
       " 'West',\n",
       " 'Mass.',\n",
       " 'factory',\n",
       " 'appears',\n",
       " 'be',\n",
       " 'highest',\n",
       " 'Western',\n",
       " 'industrialized',\n",
       " 'countries',\n",
       " 'he',\n",
       " 'plant',\n",
       " 'which',\n",
       " 'owned',\n",
       " 'by',\n",
       " '&',\n",
       " 'Co.',\n",
       " 'under',\n",
       " 'contract',\n",
       " 'probably',\n",
       " 'support',\n",
       " 'argue',\n",
       " 'U.S.',\n",
       " 'should',\n",
       " 'regulate',\n",
       " 'class',\n",
       " 'common',\n",
       " 'kind',\n",
       " 'found',\n",
       " 'most',\n",
       " 'other',\n",
       " 'buildings',\n",
       " 'one',\n",
       " 'few',\n",
       " 'nations',\n",
       " 'does',\n",
       " \"n't\",\n",
       " 'standard',\n",
       " 'regulation',\n",
       " 'smooth',\n",
       " 'fibers',\n",
       " 'such',\n",
       " 'classified',\n",
       " 'according',\n",
       " 'Brooke',\n",
       " 'T.',\n",
       " 'professor',\n",
       " 'Vermont',\n",
       " 'College',\n",
       " 'More',\n",
       " 'easily',\n",
       " 'rejected',\n",
       " 'body',\n",
       " 'explained',\n",
       " 'In',\n",
       " 'July',\n",
       " 'Environmental',\n",
       " 'Protection',\n",
       " 'Agency',\n",
       " 'imposed',\n",
       " 'gradual',\n",
       " 'ban',\n",
       " 'virtually',\n",
       " 'all',\n",
       " 'uses',\n",
       " 'By',\n",
       " '1997',\n",
       " 'almost',\n",
       " 'remaining',\n",
       " 'outlawed',\n",
       " 'About',\n",
       " '160',\n",
       " 'made',\n",
       " 'particularly',\n",
       " 'dusty',\n",
       " 'where',\n",
       " 'Workers',\n",
       " 'dumped',\n",
       " 'large',\n",
       " 'sacks',\n",
       " 'imported',\n",
       " 'material',\n",
       " 'into',\n",
       " 'huge',\n",
       " 'poured',\n",
       " 'cotton',\n",
       " 'mixed',\n",
       " 'dry',\n",
       " 'process',\n",
       " 'described',\n",
       " 'clouds',\n",
       " 'blue',\n",
       " 'dust',\n",
       " 'hung',\n",
       " 'over',\n",
       " 'parts',\n",
       " 'though',\n",
       " 'exhaust',\n",
       " 'fans',\n",
       " 'ventilated',\n",
       " 'area',\n",
       " 'question',\n",
       " 'some',\n",
       " 'managers',\n",
       " 'contracted',\n",
       " 'Phillips',\n",
       " 'vice',\n",
       " 'president',\n",
       " 'human',\n",
       " 'resources',\n",
       " 'But',\n",
       " 'you',\n",
       " 'recognize',\n",
       " 'these',\n",
       " 'events',\n",
       " 'took',\n",
       " 'place',\n",
       " '35',\n",
       " 'It',\n",
       " 'bearing',\n",
       " 'work',\n",
       " 'force',\n",
       " 'Yields',\n",
       " 'money-market',\n",
       " 'mutual',\n",
       " 'funds',\n",
       " 'continued',\n",
       " 'slide',\n",
       " 'amid',\n",
       " 'signs',\n",
       " 'portfolio',\n",
       " 'expect',\n",
       " 'further',\n",
       " 'declines',\n",
       " 'interest',\n",
       " 'rates',\n",
       " 'average',\n",
       " 'seven-day',\n",
       " 'compound',\n",
       " 'yield',\n",
       " '400',\n",
       " 'taxable',\n",
       " 'tracked',\n",
       " 'Money',\n",
       " 'Fund',\n",
       " 'Report',\n",
       " 'eased',\n",
       " 'fraction',\n",
       " 'point',\n",
       " '8.45',\n",
       " '%',\n",
       " '8.47',\n",
       " 'week',\n",
       " 'ended',\n",
       " 'Tuesday',\n",
       " 'yields',\n",
       " 'assume',\n",
       " 'reinvestment',\n",
       " 'dividends',\n",
       " 'current',\n",
       " 'continues',\n",
       " 'Average',\n",
       " 'maturity',\n",
       " \"'\",\n",
       " 'investments',\n",
       " 'lengthened',\n",
       " 'day',\n",
       " '41',\n",
       " 'days',\n",
       " 'longest',\n",
       " 'since',\n",
       " 'August',\n",
       " 'Donoghue',\n",
       " 'Longer',\n",
       " 'maturities',\n",
       " 'thought',\n",
       " 'indicate',\n",
       " 'declining',\n",
       " 'because',\n",
       " 'they',\n",
       " 'permit',\n",
       " 'retain',\n",
       " 'relatively',\n",
       " 'longer',\n",
       " 'period',\n",
       " 'considered',\n",
       " 'sign',\n",
       " 'rising',\n",
       " 'can',\n",
       " 'capture',\n",
       " 'sooner',\n",
       " 'open',\n",
       " 'only',\n",
       " 'institutions',\n",
       " 'stronger',\n",
       " 'indicator',\n",
       " 'watch',\n",
       " 'market',\n",
       " 'reached',\n",
       " 'Nevertheless',\n",
       " 'Brenda',\n",
       " 'Malizia',\n",
       " 'Negus',\n",
       " 'editor',\n",
       " 'may',\n",
       " 'blip',\n",
       " 'again',\n",
       " 'down',\n",
       " 'recent',\n",
       " 'rises',\n",
       " 'short-term',\n",
       " 'six-month',\n",
       " 'Treasury',\n",
       " 'bills',\n",
       " 'Monday',\n",
       " 'auction',\n",
       " 'example',\n",
       " 'rose',\n",
       " '8.04',\n",
       " '7.90',\n",
       " 'Despite',\n",
       " 'investors',\n",
       " 'continue',\n",
       " 'pour',\n",
       " 'cash',\n",
       " 'money',\n",
       " 'Assets',\n",
       " 'grew',\n",
       " '$',\n",
       " '1.5',\n",
       " 'during',\n",
       " 'Typically',\n",
       " 'money-fund',\n",
       " 'beat',\n",
       " 'comparable',\n",
       " 'vary',\n",
       " 'go',\n",
       " 'after',\n",
       " 'top',\n",
       " 'currently',\n",
       " 'yielding',\n",
       " 'well',\n",
       " '9',\n",
       " 'Dreyfus',\n",
       " 'Dollar',\n",
       " 'fund',\n",
       " 'had',\n",
       " '9.45',\n",
       " 'earlier',\n",
       " 'invests',\n",
       " 'heavily',\n",
       " 'dollar-denominated',\n",
       " 'securities',\n",
       " 'overseas',\n",
       " 'waiving',\n",
       " 'management',\n",
       " 'fees',\n",
       " 'boosts',\n",
       " 'simple',\n",
       " '30-day',\n",
       " 'fell',\n",
       " '8.22',\n",
       " ';',\n",
       " 'slid',\n",
       " '8.53',\n",
       " '8.56',\n",
       " 'J.P.',\n",
       " 'W.R.',\n",
       " 'Grace',\n",
       " 'holds',\n",
       " 'elected',\n",
       " 'He',\n",
       " 'succeeds',\n",
       " 'D.',\n",
       " 'formerly',\n",
       " 'resigned',\n",
       " 'Energy',\n",
       " 'seven',\n",
       " 'seats',\n",
       " 'Pacific',\n",
       " 'First',\n",
       " 'Financial',\n",
       " 'shareholders',\n",
       " 'approved',\n",
       " 'acquisition',\n",
       " 'Royal',\n",
       " 'Ltd.',\n",
       " 'Toronto',\n",
       " '27',\n",
       " 'share',\n",
       " 'or',\n",
       " 'million',\n",
       " 'thrift',\n",
       " 'holding',\n",
       " 'expects',\n",
       " 'obtain',\n",
       " 'regulatory',\n",
       " 'approval',\n",
       " 'complete',\n",
       " 'transaction',\n",
       " 'year-end',\n",
       " 'International',\n",
       " 'completed',\n",
       " 'sale',\n",
       " 'Bailey',\n",
       " 'Operations',\n",
       " 'S.p',\n",
       " 'Italian',\n",
       " 'state-owned',\n",
       " 'interests',\n",
       " 'mechanical',\n",
       " 'engineering',\n",
       " 'industry',\n",
       " 'based',\n",
       " 'Ohio',\n",
       " 'computerized',\n",
       " 'controls',\n",
       " 'systems',\n",
       " 'employs',\n",
       " '2,700',\n",
       " 'people',\n",
       " 'annual',\n",
       " 'revenue',\n",
       " '370',\n",
       " 'federal',\n",
       " 'government',\n",
       " 'suspended',\n",
       " 'sales',\n",
       " 'savings',\n",
       " 'bonds',\n",
       " 'Congress',\n",
       " 'lifted',\n",
       " 'ceiling',\n",
       " 'debt',\n",
       " 'Until',\n",
       " 'acts',\n",
       " 'authority',\n",
       " 'issue',\n",
       " 'obligations',\n",
       " 'borrowing',\n",
       " 'dropped',\n",
       " 'midnight',\n",
       " '2.80',\n",
       " 'trillion',\n",
       " '2.87',\n",
       " 'Legislation',\n",
       " 'lift',\n",
       " 'fight',\n",
       " 'cutting',\n",
       " 'capital-gains',\n",
       " 'taxes',\n",
       " 'House',\n",
       " 'voted',\n",
       " 'raise',\n",
       " '3.1',\n",
       " 'but',\n",
       " 'Senate',\n",
       " 'act',\n",
       " 'until',\n",
       " 'next',\n",
       " 'earliest',\n",
       " 'default',\n",
       " 'if',\n",
       " 'then',\n",
       " 'Clark',\n",
       " 'J.',\n",
       " 'senior',\n",
       " 'general',\n",
       " 'manager',\n",
       " 'marketing',\n",
       " 'arm',\n",
       " 'Japanese',\n",
       " 'auto',\n",
       " 'maker',\n",
       " 'Mazda',\n",
       " 'Motor',\n",
       " 'Corp',\n",
       " 'position',\n",
       " 'oversee',\n",
       " 'service',\n",
       " 'operations',\n",
       " 'Previously',\n",
       " '43',\n",
       " 'Chrysler',\n",
       " 'division',\n",
       " 'been',\n",
       " 'executive',\n",
       " '20',\n",
       " 'When',\n",
       " 'time',\n",
       " 'their',\n",
       " 'nation',\n",
       " 'manufacturing',\n",
       " 'titans',\n",
       " 'typically',\n",
       " 'jet',\n",
       " 'off',\n",
       " 'sunny',\n",
       " 'resort',\n",
       " 'towns',\n",
       " 'like',\n",
       " 'Boca',\n",
       " 'Hot',\n",
       " 'Springs',\n",
       " 'Not',\n",
       " 'Association',\n",
       " 'Manufacturers',\n",
       " 'settled',\n",
       " 'capital',\n",
       " 'Indianapolis',\n",
       " 'fall',\n",
       " 'meeting',\n",
       " 'And',\n",
       " 'city',\n",
       " 'decided',\n",
       " 'treat',\n",
       " 'guests',\n",
       " 'royalty',\n",
       " 'rock',\n",
       " 'stars',\n",
       " 'owners',\n",
       " 'idea',\n",
       " 'course',\n",
       " ':',\n",
       " 'prove',\n",
       " '125',\n",
       " 'corporate',\n",
       " 'decision',\n",
       " 'makers',\n",
       " 'buckle',\n",
       " 'Belt',\n",
       " 'so',\n",
       " 'good',\n",
       " 'expand',\n",
       " 'On',\n",
       " 'receiving',\n",
       " 'end',\n",
       " 'message',\n",
       " 'officials',\n",
       " 'giants',\n",
       " 'Du',\n",
       " 'Pont',\n",
       " 'along',\n",
       " 'lesser',\n",
       " 'Steel',\n",
       " 'Valley',\n",
       " 'Queen',\n",
       " 'Factory',\n",
       " 'For',\n",
       " 'starters',\n",
       " 'executives',\n",
       " 'joined',\n",
       " 'Mayor',\n",
       " 'William',\n",
       " 'H.',\n",
       " 'III',\n",
       " 'evening',\n",
       " 'guest',\n",
       " 'Victor',\n",
       " 'Champagne',\n",
       " 'followed',\n",
       " 'morning',\n",
       " 'police',\n",
       " 'wives',\n",
       " 'traffic',\n",
       " 'red',\n",
       " 'lights',\n",
       " 'governor',\n",
       " 'could',\n",
       " 'welcomed',\n",
       " 'special',\n",
       " 'buffet',\n",
       " 'breakfast',\n",
       " 'held',\n",
       " 'museum',\n",
       " 'food',\n",
       " 'drinks',\n",
       " 'banned',\n",
       " 'everyday',\n",
       " 'visitors',\n",
       " 'Then',\n",
       " 'honor',\n",
       " 'out',\n",
       " 'four',\n",
       " 'drivers',\n",
       " 'crews',\n",
       " 'official',\n",
       " '500',\n",
       " 'announcer',\n",
       " 'exhibition',\n",
       " 'race',\n",
       " 'After',\n",
       " 'Fortune',\n",
       " 'cars',\n",
       " 'No',\n",
       " 'pointed',\n",
       " 'still',\n",
       " 'space',\n",
       " 'machines',\n",
       " 'another',\n",
       " 'sponsor',\n",
       " 'name',\n",
       " 'two',\n",
       " 'Back',\n",
       " 'downtown',\n",
       " 'squeezed',\n",
       " 'meetings',\n",
       " 'hotel',\n",
       " 'buses',\n",
       " 'dinner',\n",
       " 'dancing',\n",
       " 'block',\n",
       " 'away',\n",
       " 'Under',\n",
       " 'moons',\n",
       " 'Indiana',\n",
       " 'ballroom',\n",
       " 'nine',\n",
       " 'hottest',\n",
       " 'chefs',\n",
       " 'town',\n",
       " 'fed',\n",
       " 'them',\n",
       " 'chocolate',\n",
       " 'free',\n",
       " 'meal',\n",
       " 'when',\n",
       " 'eat',\n",
       " 'gave',\n",
       " 'standing',\n",
       " 'say',\n",
       " 'treatment',\n",
       " 'return',\n",
       " 'future',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'winter',\n",
       " 'February',\n",
       " 'South',\n",
       " 'Korea',\n",
       " 'registered',\n",
       " 'trade',\n",
       " 'deficit',\n",
       " '101',\n",
       " 'October',\n",
       " 'reflecting',\n",
       " 'country',\n",
       " 'economic',\n",
       " 'sluggishness',\n",
       " 'figures',\n",
       " 'released',\n",
       " 'Wednesday',\n",
       " 'Trade',\n",
       " 'Industry',\n",
       " 'Ministry',\n",
       " 'showed',\n",
       " 'fifth',\n",
       " 'monthly',\n",
       " 'setback',\n",
       " 'casting',\n",
       " 'cloud',\n",
       " 'economy',\n",
       " 'Exports',\n",
       " 'stood',\n",
       " 'mere',\n",
       " '0.7',\n",
       " 'increase',\n",
       " 'while',\n",
       " 'imports',\n",
       " 'increased',\n",
       " 'sharply',\n",
       " 'last',\n",
       " 'boom',\n",
       " 'began',\n",
       " '1986',\n",
       " 'prolonged',\n",
       " 'labor',\n",
       " 'disputes',\n",
       " 'conflicts',\n",
       " 'sluggish',\n",
       " 'exports',\n",
       " 'Government',\n",
       " 'would',\n",
       " 'remain',\n",
       " 'target',\n",
       " '68',\n",
       " 'gloomy',\n",
       " 'forecast',\n",
       " 'recorded',\n",
       " 'surplus',\n",
       " '71',\n",
       " 'January',\n",
       " 'accumulated',\n",
       " '4',\n",
       " 'same',\n",
       " 'Imports',\n",
       " '19',\n",
       " 'Newsweek',\n",
       " 'trying',\n",
       " 'keep',\n",
       " 'pace',\n",
       " 'rival',\n",
       " 'Time',\n",
       " 'magazine',\n",
       " 'announced',\n",
       " 'advertising',\n",
       " '1990',\n",
       " 'introduce',\n",
       " 'incentive',\n",
       " 'plan',\n",
       " 'advertisers',\n",
       " 'ad',\n",
       " 'Washington',\n",
       " 'Post',\n",
       " 'second',\n",
       " 'offered',\n",
       " 'Plans',\n",
       " 'give',\n",
       " 'discounts',\n",
       " 'maintaining',\n",
       " 'increasing',\n",
       " 'spending',\n",
       " 'become',\n",
       " 'permanent',\n",
       " 'news',\n",
       " 'weeklies',\n",
       " 'underscore',\n",
       " 'fierce',\n",
       " 'competition',\n",
       " 'between',\n",
       " 'Warner',\n",
       " 'Mortimer',\n",
       " 'B.',\n",
       " 'News',\n",
       " 'World',\n",
       " 'Alan',\n",
       " 'Spoon',\n",
       " '5',\n",
       " 'full',\n",
       " 'page',\n",
       " 'cost',\n",
       " 'mid-October',\n",
       " 'lowered',\n",
       " 'guaranteed',\n",
       " 'circulation',\n",
       " 'base',\n",
       " 'not',\n",
       " 'lower',\n",
       " 'effectively',\n",
       " '7.5',\n",
       " 'per',\n",
       " 'subscriber',\n",
       " 'costs',\n",
       " '120,000',\n",
       " 'yet',\n",
       " 'announce',\n",
       " 'Credit',\n",
       " 'Plan',\n",
       " 'awards',\n",
       " 'credits',\n",
       " 'renewal',\n",
       " 'reward',\n",
       " 'bonuses',\n",
       " 'meet',\n",
       " 'exceed',\n",
       " '1989',\n",
       " 'long',\n",
       " 'spent',\n",
       " 'attempt',\n",
       " 'shore',\n",
       " 'decline',\n",
       " 'pages',\n",
       " 'first',\n",
       " 'months',\n",
       " 'totaled',\n",
       " 'drop',\n",
       " '3.2',\n",
       " 'Publishers',\n",
       " 'Information',\n",
       " 'Bureau',\n",
       " 'What',\n",
       " 'matters',\n",
       " 'what',\n",
       " 'paying',\n",
       " 'department',\n",
       " 'we',\n",
       " 'doing',\n",
       " 'fine',\n",
       " 'Both',\n",
       " 'gaining',\n",
       " 'without',\n",
       " 'heavy',\n",
       " 'use',\n",
       " 'electronic',\n",
       " 'subscribers',\n",
       " 'telephones',\n",
       " 'watches',\n",
       " 'However',\n",
       " 'none',\n",
       " 'big',\n",
       " 'gains',\n",
       " 'According',\n",
       " 'largest',\n",
       " 'decrease',\n",
       " '7.3',\n",
       " 'six',\n",
       " 'flat',\n",
       " '2.6',\n",
       " 'Electric',\n",
       " 'System',\n",
       " 'bowed',\n",
       " 'bidding',\n",
       " 'Public',\n",
       " 'Service',\n",
       " 'Hampshire',\n",
       " 'saying',\n",
       " 'risks',\n",
       " 'too',\n",
       " 'potential',\n",
       " 'justify',\n",
       " 'offer',\n",
       " 'move',\n",
       " 'leaves',\n",
       " 'United',\n",
       " 'Illuminating',\n",
       " 'Northeast',\n",
       " 'Utilities',\n",
       " 'outside',\n",
       " 'bidders',\n",
       " 'PS',\n",
       " 'also',\n",
       " 'proposed',\n",
       " 'internal',\n",
       " 'reorganization',\n",
       " 'Chapter',\n",
       " '11',\n",
       " 'bankruptcy',\n",
       " 'proceedings',\n",
       " 'independent',\n",
       " 'Westborough',\n",
       " '2',\n",
       " 'acquire',\n",
       " 'below',\n",
       " '2.29',\n",
       " 'value',\n",
       " 'places',\n",
       " 'bid',\n",
       " '2.25',\n",
       " 'says',\n",
       " 'worth',\n",
       " 'Haven',\n",
       " 'Conn.',\n",
       " 'Hartford',\n",
       " 'Conn',\n",
       " 'N.H.',\n",
       " 'values',\n",
       " '2.2',\n",
       " 'John',\n",
       " 'Rowe',\n",
       " 'chief',\n",
       " 'officer',\n",
       " 'equity',\n",
       " 'suffer',\n",
       " 'forecasts',\n",
       " 'related',\n",
       " 'growth',\n",
       " 'electricity',\n",
       " 'demand',\n",
       " 'improved',\n",
       " 'operating',\n",
       " 'did',\n",
       " 'come',\n",
       " 'true',\n",
       " 'evaluated',\n",
       " 'raising',\n",
       " 'seemed',\n",
       " 'substantial',\n",
       " 'persistent',\n",
       " 'rewards',\n",
       " 'way',\n",
       " ...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_frequent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d9bc020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file pos\n",
    "pos_distinct = []\n",
    "\n",
    "#with open('recap/pos.txt', 'r') as pos_txt:\n",
    "with open('output/pos.txt', 'r') as pos_txt:\n",
    "    for pos in pos_txt:\n",
    "        pos = pos.strip('\\n')\n",
    "        pos_distinct.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cf57f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file hmm                \n",
    "#with open('recap/hmm.json', 'r') as hmm:\n",
    "with open('output/hmm.json', 'r') as hmm:\n",
    "    json_data = json.load(hmm)\n",
    "\n",
    "emission, transition = json_data[0], json_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1af28d51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Corporations</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Commission</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>authorized</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          word  POS\n",
       "0      1           The   DT\n",
       "1      2       Arizona  NNP\n",
       "2      3  Corporations  NNP\n",
       "3      4    Commission  NNP\n",
       "4      5    authorized  VBD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev = pd.read_csv('hw3/data/dev', sep='\\t', names=['index', 'word', 'POS'])\n",
    "dev = pd.read_csv('data/dev', sep='\\t', names=['index', 'word', 'POS'])\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e465817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dev = dev.loc[:, 'index'].values.tolist()\n",
    "word_dev = dev.loc[:, 'word'].values.tolist()\n",
    "pos_dev = dev.loc[:, 'POS'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77133e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dev lists (index, word and pos) to individual samples (list --> list of sublists)\n",
    "word_dev2 = []\n",
    "pos_dev2 = []\n",
    "word_sample = []\n",
    "pos_sample = []\n",
    "for i in range(len(dev)-1):\n",
    "    if index_dev[i] < index_dev[i+1]:\n",
    "        word_sample.append(word_dev[i])\n",
    "        pos_sample.append(pos_dev[i])\n",
    "    else:\n",
    "        word_sample.append(word_dev[i])\n",
    "        word_dev2.append(word_sample)\n",
    "        word_sample = []\n",
    "        \n",
    "        pos_sample.append(pos_dev[i])\n",
    "        pos_dev2.append(pos_sample)\n",
    "        pos_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a31d670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy(sentence):\n",
    "    # initialize a dictionary to keep track of the pos for each position\n",
    "    pos = []\n",
    "    \n",
    "    # predict the pos of the first word in the sentence\n",
    "    \n",
    "    # we need to make sure the first word is in the vocabulary. If not, replace\n",
    "    # with <unk>\n",
    "    if sentence[0] not in vocab_frequent:\n",
    "        sentence[0] = '<unk>'\n",
    "    # predict pos based on the product of the emission and transition\n",
    "    max_prob = 0\n",
    "    p0 = 'UNK'\n",
    "    \n",
    "    for p in pos_distinct:\n",
    "        try:\n",
    "            temp = emission[sentence[0] + '|' + p] * transition[p + '|' + '<s>']\n",
    "            if temp > max_prob:\n",
    "                max_prob = temp\n",
    "                p0 = p\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    pos.append(p0)\n",
    "    \n",
    "    # predict the pos of the remaining words\n",
    "    \n",
    "    \n",
    "    for i in range(1, len(sentence)):\n",
    "        # again, we need to check the existence of the word in the vocabulary.\n",
    "        if sentence[i] not in vocab_frequent:\n",
    "            sentence[i] = '<unk>'\n",
    "        \n",
    "        max_prob = 0\n",
    "        pi = 'UNK'\n",
    "        \n",
    "        for p in pos_distinct:\n",
    "            try:\n",
    "                temp = emission[sentence[i] + '|' + p] * transition[p + '|' + pos[-1]]\n",
    "                if temp > max_prob:\n",
    "                    max_prob = temp\n",
    "                    pi = p\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "        pos.append(pi)\n",
    "    \n",
    "    return pos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65c9e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_greedy = [greedy(s) for s in word_dev2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6dca109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the list of sublists into one single list\n",
    "pos_greedy = fc.reduce(lambda a, b: a + b, pos_greedy)\n",
    "pos_dev = fc.reduce(lambda a, b: a + b, pos_dev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb9cfc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy on the dev data is 92.67%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(pos_dev, pos_greedy)\n",
    "print('The prediction accuracy on the dev data is {:.2f}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f193e38",
   "metadata": {},
   "source": [
    "## Task 4: Viterbi Decoding with HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "519338b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file vocab\n",
    "vocab_frequent = []\n",
    "#with open('recap/vocab_frequent.txt', 'r') as vocab_txt:\n",
    "with open('output/vocab_frequent.txt', 'r') as vocab_txt:\n",
    "    for word in vocab_txt:\n",
    "        word = word.strip('\\n')\n",
    "        vocab_frequent.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "648c72e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load txt file pos\n",
    "pos_distinct = []\n",
    "\n",
    "#with open('recap/pos.txt', 'r') as pos_txt:\n",
    "with open('output/pos.txt', 'r') as pos_txt:\n",
    "    for pos in pos_txt:\n",
    "        pos = pos.strip('\\n')\n",
    "        pos_distinct.append(pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9699a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file hmm                \n",
    "#with open('recap/hmm.json', 'r') as hmm:\n",
    "with open('output/hmm.json', 'r') as hmm:\n",
    "    json_data = json.load(hmm)\n",
    "\n",
    "emission, transition = json_data[0], json_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30f8f663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Corporations</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Commission</td>\n",
       "      <td>NNP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>authorized</td>\n",
       "      <td>VBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index          word  POS\n",
       "0      1           The   DT\n",
       "1      2       Arizona  NNP\n",
       "2      3  Corporations  NNP\n",
       "3      4    Commission  NNP\n",
       "4      5    authorized  VBD"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dev = pd.read_csv('hw3/data/dev', sep='\\t', names=['index', 'word', 'POS'])\n",
    "dev = pd.read_csv('data/dev', sep='\\t', names=['index', 'word', 'POS'])\n",
    "dev.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46fa689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_dev = dev.loc[:, 'index'].values.tolist()\n",
    "word_dev = dev.loc[:, 'word'].values.tolist()\n",
    "pos_dev = dev.loc[:, 'POS'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "000ffb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dev lists (index, word and pos) to individual samples (list --> list of sublists)\n",
    "word_dev2 = []\n",
    "pos_dev2 = []\n",
    "word_sample = []\n",
    "pos_sample = []\n",
    "for i in range(len(dev)-1):\n",
    "    if index_dev[i] < index_dev[i+1]:\n",
    "        word_sample.append(word_dev[i])\n",
    "        pos_sample.append(pos_dev[i])\n",
    "    else:\n",
    "        word_sample.append(word_dev[i])\n",
    "        word_dev2.append(word_sample)\n",
    "        word_sample = []\n",
    "        \n",
    "        pos_sample.append(pos_dev[i])\n",
    "        pos_dev2.append(pos_sample)\n",
    "        pos_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1d76cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to predict the pos for an input sentence\n",
    "def viterbi(sentence):\n",
    "    # initialize a dictionary that keeps track of the highest cumulative probability of each possible\n",
    "    # pos at each position of the input sentence\n",
    "    seq = {i:{} for i in range(len(sentence))}\n",
    "    # also initialize a dictionary that keeps track of the pos of the previous pos that leads to the\n",
    "    # highest cumulative probability of each possible pos at each position of the input sentence\n",
    "    # for instance, for a pos of NNP at position i, we want to know which pos of position i-1 leads to\n",
    "    # the highest cumulative probability of NNP at position i.\n",
    "    pre_pos = {i:{} for i in range(len(sentence))}    \n",
    "    \n",
    "    # for the first position, the highest cumulative probability of each possible pos would be\n",
    "    # emission[sentence[0]|pos] * transition[pos|<s>]\n",
    "    \n",
    "    # check if the first word is in the vocabualry. If not, replace with '<unk>'\n",
    "    if sentence[0] not in vocab_frequent:\n",
    "        sentence[0] = '<unk>'\n",
    "        \n",
    "    for p in pos_distinct:\n",
    "        if p + '|' + '<s>' in transition:\n",
    "            try:\n",
    "                seq[0][p] = transition[p + '|' + '<s>'] * \\\n",
    "                            emission[sentence[0] + '|' + p]\n",
    "            except:\n",
    "                seq[0][p] = 0\n",
    "    # set <s> as the previous pos of each possible pos at the first position\n",
    "    for p in seq[0].keys():\n",
    "        pre_pos[0][p] = '<s>'\n",
    "    \n",
    "    # for position i > 0, the highest cumulative probability of each possible pos would be\n",
    "    # emission[sentence[i]|pos[i]] * transition[pos[i]|pos[i-1]] * seq[i-1][pos]\n",
    "    for i in range(1, len(sentence)):\n",
    "        # still, check if the word is in the vocabulary\n",
    "        if sentence[i] not in vocab_frequent:\n",
    "            sentence[i] = '<unk>'\n",
    "            \n",
    "        for p in seq[i-1].keys():\n",
    "            for p_prime in pos_distinct:\n",
    "                if p_prime + '|' + p in transition:\n",
    "                    if p_prime in seq[i]:\n",
    "                        try:\n",
    "                            temp = seq[i-1][p] * \\\n",
    "                                   transition[p_prime + '|' + p] * \\\n",
    "                                   emission[sentence[i] + '|' + p_prime]\n",
    "                            if  temp > seq[i][p_prime]:\n",
    "                                seq[i][p_prime] = temp\n",
    "                                pre_pos[i][p_prime] = p\n",
    "                        except:\n",
    "                            pass\n",
    "                    else:\n",
    "                        try:\n",
    "                            seq[i][p_prime] = seq[i-1][p] * \\\n",
    "                                              transition[p_prime + '|' + p] * \\\n",
    "                                              emission[sentence[i] + '|' + p_prime]\n",
    "                            pre_pos[i][p_prime] = p\n",
    "                        except:\n",
    "                            seq[i][p_prime] = 0\n",
    "    # after we get the maximum probability for every possible pos at every position of a sentence,\n",
    "    # we can trace backward to find out our prediction on the pos for the sentence.\n",
    "    seq_predict = []\n",
    "    \n",
    "    # The pos of the last word in the sentence is the one with the highest probability\n",
    "    # after predicting the pos of the last word in the sentence, we can iterate through pre_pos to predict\n",
    "    # the pos of the remaining words in the input sentence in the reverse order\n",
    "    \n",
    "    # the highest probability\n",
    "    prob_max = max(seq[len(sentence)-1].values())\n",
    "    # the index of the highest probability\n",
    "    index_max = list(seq[len(sentence)-1].values()).index(prob_max)\n",
    "    # the pos of the highest probability\n",
    "    pos_max = list(seq[len(sentence)-1].keys())[index_max]\n",
    "    seq_predict.append(pos_max)\n",
    "    \n",
    "    # iterate through pre_pos\n",
    "    for i in range(len(sentence)-1, 0, -1):\n",
    "        # for some rare ss or sx pairs, there is no corresponding key in the\n",
    "        # transition or emission dictionary. In this case, we need to set manually\n",
    "        # the pos to 'UNK' at those positions\n",
    "        try:\n",
    "            pos_max = pre_pos[i][pos_max]\n",
    "            seq_predict.append(pos_max)\n",
    "        except:\n",
    "            seq_predict.append('UNK')\n",
    "        \n",
    "    # The final seq_predict should be the reverse of the original\n",
    "    seq_predict = [seq_predict[i] for i in range(len(seq_predict)-1, -1, -1)]\n",
    "    return seq_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67047401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use viterbi to predict pos for dev\n",
    "pos_viterbi = [viterbi(s) for s in word_dev2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41f61c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the list of sublists to a single list\n",
    "pos_viterbi = fc.reduce(lambda a, b: a + b, pos_viterbi)\n",
    "pos_dev = fc.reduce(lambda a, b: a + b, pos_dev2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3f01caa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction accuracy on the dev data is 94.36%\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(pos_dev, pos_viterbi)\n",
    "print('The prediction accuracy on the dev data is {:.2f}%'.format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfcfa8e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
